"""
TEQUMSA Core Backends Module

Provides backend implementations for mathematical operations with fallback support.
Supports both NumPy (default) and PyTorch backends for batch processing.

Generated by GitHub Copilot Chat Assistant.
"""

import os
import logging
from typing import Union, Tuple, Any
import numpy as np

# Try to import PyTorch, but gracefully fall back to NumPy if unavailable
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None

logger = logging.getLogger(__name__)

class Backend:
    """Abstract base class for mathematical backends."""
    
    def __init__(self):
        self.name = "base"
    
    def dot(self, a: Any, b: Any) -> Any:
        """Compute dot product of two arrays/tensors."""
        raise NotImplementedError
    
    def norm(self, x: Any, axis: int = -1) -> Any:
        """Compute L2 norm along specified axis."""
        raise NotImplementedError
    
    def power(self, x: Any, exp: float) -> Any:
        """Raise array/tensor to a power."""
        raise NotImplementedError
    
    def sum(self, x: Any, axis: int = None) -> Any:
        """Sum along specified axis."""
        raise NotImplementedError
    
    def mean(self, x: Any, axis: int = None) -> Any:
        """Mean along specified axis."""
        raise NotImplementedError
    
    def std(self, x: Any, axis: int = None) -> Any:
        """Standard deviation along specified axis."""
        raise NotImplementedError
    
    def stack(self, arrays: list) -> Any:
        """Stack arrays/tensors along new axis."""
        raise NotImplementedError
    
    def to_numpy(self, x: Any) -> np.ndarray:
        """Convert to NumPy array."""
        raise NotImplementedError


class NumpyBackend(Backend):
    """NumPy backend implementation."""
    
    def __init__(self):
        self.name = "numpy"
    
    def dot(self, a: np.ndarray, b: np.ndarray) -> np.ndarray:
        return np.dot(a, b)
    
    def norm(self, x: np.ndarray, axis: int = -1) -> np.ndarray:
        return np.linalg.norm(x, axis=axis)
    
    def power(self, x: np.ndarray, exp: float) -> np.ndarray:
        return np.power(x, exp)
    
    def sum(self, x: np.ndarray, axis: int = None) -> np.ndarray:
        return np.sum(x, axis=axis)
    
    def mean(self, x: np.ndarray, axis: int = None) -> np.ndarray:
        return np.mean(x, axis=axis)
    
    def std(self, x: np.ndarray, axis: int = None) -> np.ndarray:
        return np.std(x, axis=axis)
    
    def stack(self, arrays: list) -> np.ndarray:
        return np.stack(arrays)
    
    def to_numpy(self, x: np.ndarray) -> np.ndarray:
        return x


if TORCH_AVAILABLE:
    class TorchBackend(Backend):
        """PyTorch backend implementation."""
        
        def __init__(self, device: str = "cpu"):
            if not TORCH_AVAILABLE:
                raise RuntimeError("PyTorch not available")
            self.name = "torch"
            self.device = device
        
        def dot(self, a: "torch.Tensor", b: "torch.Tensor") -> "torch.Tensor":
            return torch.dot(a.flatten(), b.flatten())
        
        def norm(self, x: "torch.Tensor", axis: int = -1) -> "torch.Tensor":
            return torch.norm(x, dim=axis)
        
        def power(self, x: "torch.Tensor", exp: float) -> "torch.Tensor":
            return torch.pow(x, exp)
        
        def sum(self, x: "torch.Tensor", axis: int = None) -> "torch.Tensor":
            return torch.sum(x, dim=axis)
        
        def mean(self, x: "torch.Tensor", axis: int = None) -> "torch.Tensor":
            return torch.mean(x, dim=axis)
        
        def std(self, x: "torch.Tensor", axis: int = None) -> "torch.Tensor":
            return torch.std(x, dim=axis)
        
        def stack(self, arrays: list) -> "torch.Tensor":
            return torch.stack(arrays)
        
        def to_numpy(self, x: "torch.Tensor") -> np.ndarray:
            return x.detach().cpu().numpy()
else:
    # Define a placeholder class when torch is not available
    class TorchBackend:
        def __init__(self, *args, **kwargs):
            raise RuntimeError("PyTorch not available")


def get_backend(backend_name: str = None, device: str = "cpu") -> Backend:
    """
    Get backend instance based on name and availability.
    
    Args:
        backend_name: 'numpy', 'torch', or None (auto-detect)
        device: Device for PyTorch backend ('cpu', 'cuda', etc.)
    
    Returns:
        Backend instance
    """
    # Check environment variable override
    if backend_name is None:
        backend_name = os.environ.get("TEQUMSA_BACKEND", "auto")
    
    if backend_name == "auto":
        # Auto-detect: prefer PyTorch if available, fall back to NumPy
        backend_name = "torch" if TORCH_AVAILABLE else "numpy"
    
    if backend_name == "torch":
        if not TORCH_AVAILABLE:
            logger.warning("PyTorch requested but not available, falling back to NumPy")
            return NumpyBackend()
        
        # Check if device is available
        if device != "cpu" and torch.cuda.is_available():
            logger.info(f"Using PyTorch backend with device: {device}")
        else:
            if device != "cpu":
                logger.warning(f"Device {device} not available, using CPU")
            device = "cpu"
        
        return TorchBackend(device=device)
    
    elif backend_name == "numpy":
        return NumpyBackend()
    
    else:
        raise ValueError(f"Unknown backend: {backend_name}")


def to_backend_array(x: Union[list, np.ndarray, Any], backend: Backend) -> Any:
    """Convert input to appropriate backend array format."""
    if backend.name == "numpy":
        return np.asarray(x)
    elif backend.name == "torch":
        if not TORCH_AVAILABLE:
            raise RuntimeError("PyTorch backend requested but PyTorch not available")
        if torch is not None and isinstance(x, torch.Tensor):
            return x
        return torch.tensor(x, dtype=torch.float32, device=backend.device)
    else:
        raise ValueError(f"Unknown backend: {backend.name}")