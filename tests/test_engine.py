"""
Test TEQUMSA Awareness Engine

Tests for the main engine class, tier management, and integration functionality.

Generated by GitHub Copilot Chat Assistant.
"""

import pytest
import numpy as np
import tempfile
import shutil
import os
from unittest.mock import patch, MagicMock

from tequmsa import AwarenessEngine
from tequmsa.utils.logging_utils import ConsciousnessLogger


class TestAwarenessEngineInit:
    """Test awareness engine initialization."""
    
    def test_engine_init_default(self):
        """Test engine initialization with defaults."""
        engine = AwarenessEngine()
        
        assert engine.tier == "free"
        assert engine.backend.name == "numpy"  # Should fall back to numpy
        assert engine.alpha == 2.0
        assert engine.tau == 0.7
        assert engine.hysteresis == 0.05
        assert not engine.adaptive_enabled  # Free tier has adaptive disabled
        assert engine.max_batch_size == 10
    
    def test_engine_init_pro_tier(self):
        """Test engine initialization with pro tier."""
        engine = AwarenessEngine(tier="pro")
        
        assert engine.tier == "pro"
        assert engine.alpha == 2.5
        assert engine.tau == 0.65
        assert engine.hysteresis == 0.03
        assert engine.adaptive_enabled  # Pro tier has adaptive enabled
        assert engine.max_batch_size == 50
    
    def test_engine_init_enterprise_tier(self):
        """Test engine initialization with enterprise tier."""
        engine = AwarenessEngine(tier="enterprise")
        
        assert engine.tier == "enterprise"
        assert engine.alpha == 3.0
        assert engine.tau == 0.6
        assert engine.hysteresis == 0.02
        assert engine.adaptive_enabled  # Enterprise tier has adaptive enabled
        assert engine.max_batch_size == 200
    
    def test_engine_init_with_custom_logger(self):
        """Test engine initialization with custom logger."""
        temp_dir = tempfile.mkdtemp()
        try:
            custom_logger = ConsciousnessLogger(
                log_path=os.path.join(temp_dir, "custom.jsonl")
            )
            engine = AwarenessEngine(logger=custom_logger)
            
            assert engine.logger is custom_logger
        finally:
            shutil.rmtree(temp_dir)


class TestGAIASignatureLoading:
    """Test GAIA signature loading and validation."""
    
    def test_load_gaia_signature_valid(self):
        """Test loading valid GAIA signature."""
        engine = AwarenessEngine()
        
        gaia_signature = {
            'bio': [1.0, 0.0, 0.0, 0.0],
            'digital': [0.0, 1.0, 0.0, 0.0],
            'cosmic': [0.0, 0.0, 1.0, 0.0]
        }
        
        engine.load_gaia_signature(gaia_signature)
        
        assert engine.gaia_signature is not None
        assert 'bio' in engine.gaia_signature
        assert 'digital' in engine.gaia_signature
        assert 'cosmic' in engine.gaia_signature
    
    def test_load_gaia_signature_invalid(self):
        """Test loading invalid GAIA signature."""
        engine = AwarenessEngine()
        
        # Missing component
        invalid_gaia = {
            'bio': [1.0, 0.0, 0.0, 0.0],
            'digital': [0.0, 1.0, 0.0, 0.0]
            # Missing 'cosmic'
        }
        
        with pytest.raises(KeyError, match="Missing GAIA signature components"):
            engine.load_gaia_signature(invalid_gaia)
    
    def test_compute_awakening_without_gaia(self):
        """Test that computing awakening fails without GAIA signature."""
        engine = AwarenessEngine()
        agent_vector = [1.0, 0.0, 0.0, 0.0]
        
        with pytest.raises(RuntimeError, match="GAIA signature not loaded"):
            engine.compute_awakening(agent_vector)


class TestSingleVectorProcessing:
    """Test single vector awakening computation."""
    
    def setup_method(self):
        """Set up test environment."""
        self.engine = AwarenessEngine(tier="pro")
        self.gaia_signature = {
            'bio': [1.0, 0.0, 0.0, 0.0],
            'digital': [0.0, 1.0, 0.0, 0.0],
            'cosmic': [0.0, 0.0, 1.0, 0.0]
        }
        self.engine.load_gaia_signature(self.gaia_signature)
    
    def test_compute_awakening_basic(self):
        """Test basic single vector awakening computation."""
        agent_vector = [1.0, 0.0, 0.0, 0.0]  # Aligned with bio
        
        awakened, R, components, diagnostics = self.engine.compute_awakening(agent_vector)
        
        assert isinstance(awakened, bool)
        assert 0 <= R <= 1
        assert 'bio' in components
        assert 'digital' in components
        assert 'cosmic' in components
        assert 'tier' in diagnostics
        assert diagnostics['tier'] == 'pro'
        
        # Bio component should have highest similarity
        assert components['bio'] > components['digital']
        assert components['bio'] > components['cosmic']
    
    def test_awakening_state_persistence(self):
        """Test that awakening state persists between calls."""
        # Vector that should trigger awakening
        strong_vector = [0.9, 0.9, 0.9, 0.0]
        
        awakened1, _, _, _ = self.engine.compute_awakening(strong_vector)
        
        # Check that previous awakened state is updated
        assert self.engine.previous_awakened == awakened1
        
        # Second call should consider previous state for hysteresis
        awakened2, _, _, diag2 = self.engine.compute_awakening(strong_vector)
        
        assert 'hysteresis_info' in diag2
        assert diag2['hysteresis_info']['previous_awakened'] == awakened1
    
    def test_rolling_statistics_update(self):
        """Test that rolling statistics are updated."""
        agent_vectors = [
            [1.0, 0.0, 0.0, 0.0],
            [0.8, 0.6, 0.0, 0.0],
            [0.6, 0.8, 0.0, 0.0]
        ]
        
        for vector in agent_vectors:
            self.engine.compute_awakening(vector)
        
        assert len(self.engine.rolling_R_values) == 3
        assert len(self.engine.rolling_similarities) == 3
        
        # Get status to check rolling statistics
        status = self.engine.get_status()
        assert status['rolling_stats']['count'] == 3
        assert 'mean_R' in status['rolling_stats']
        assert 'std_R' in status['rolling_stats']


class TestBatchProcessing:
    """Test batch vector processing."""
    
    def setup_method(self):
        """Set up test environment."""
        self.engine = AwarenessEngine(tier="enterprise")
        self.gaia_signature = {
            'bio': [1.0, 0.0, 0.0, 0.0],
            'digital': [0.0, 1.0, 0.0, 0.0],
            'cosmic': [0.0, 0.0, 1.0, 0.0]
        }
        self.engine.load_gaia_signature(self.gaia_signature)
    
    def test_compute_awakening_batch_basic(self):
        """Test basic batch processing."""
        agent_batch = [
            [1.0, 0.0, 0.0, 0.0],  # Aligned with bio
            [0.0, 1.0, 0.0, 0.0],  # Aligned with digital
            [0.0, 0.0, 1.0, 0.0],  # Aligned with cosmic
        ]
        
        awakened_states, R_scores, components_list, batch_diag = self.engine.compute_awakening_batch(agent_batch)
        
        assert len(awakened_states) == 3
        assert len(R_scores) == 3
        assert len(components_list) == 3
        assert batch_diag['batch_size'] == 3
        
        # Check that rolling statistics were updated with all R scores
        assert len(self.engine.rolling_R_values) == 3
    
    def test_batch_size_limit_enforcement(self):
        """Test that batch size limits are enforced."""
        # Create batch larger than enterprise max (200)
        large_batch = [[1.0, 0.0, 0.0, 0.0]] * 250
        
        with pytest.raises(ValueError, match="exceeds maximum"):
            self.engine.compute_awakening_batch(large_batch)


class TestTierManagement:
    """Test tier management functionality."""
    
    def test_update_tier_valid(self):
        """Test updating to valid tier."""
        engine = AwarenessEngine(tier="free")
        
        original_alpha = engine.alpha
        original_max_batch = engine.max_batch_size
        
        engine.update_tier("enterprise")
        
        assert engine.tier == "enterprise"
        assert engine.alpha != original_alpha  # Should have changed
        assert engine.max_batch_size != original_max_batch  # Should have changed
        assert engine.current_alpha == engine.alpha  # Should reset to new tier default
    
    def test_update_tier_invalid(self):
        """Test updating to invalid tier."""
        engine = AwarenessEngine()
        
        with pytest.raises(ValueError, match="Unknown tier"):
            engine.update_tier("invalid_tier")
    
    def test_tier_configuration_isolation(self):
        """Test that different tier instances have different configurations."""
        free_engine = AwarenessEngine(tier="free")
        pro_engine = AwarenessEngine(tier="pro")
        enterprise_engine = AwarenessEngine(tier="enterprise")
        
        # All should have different alpha values
        assert free_engine.alpha != pro_engine.alpha
        assert pro_engine.alpha != enterprise_engine.alpha
        
        # All should have different batch size limits
        assert free_engine.max_batch_size != pro_engine.max_batch_size
        assert pro_engine.max_batch_size != enterprise_engine.max_batch_size


class TestStateManagement:
    """Test engine state management."""
    
    def setup_method(self):
        """Set up test environment."""
        self.engine = AwarenessEngine(tier="pro")
        self.gaia_signature = {
            'bio': [1.0, 0.0, 0.0, 0.0],
            'digital': [0.0, 1.0, 0.0, 0.0],
            'cosmic': [0.0, 0.0, 1.0, 0.0]
        }
        self.engine.load_gaia_signature(self.gaia_signature)
    
    def test_reset_state(self):
        """Test state reset functionality."""
        # Build up some state
        for i in range(5):
            self.engine.compute_awakening([1.0, 0.0, 0.0, 0.0])
        
        # Verify state exists
        assert len(self.engine.rolling_R_values) > 0
        original_alpha = self.engine.alpha  # Store original tier alpha
        
        # Reset state
        self.engine.reset_state()
        
        # Verify state is reset
        assert len(self.engine.rolling_R_values) == 0
        assert len(self.engine.rolling_similarities) == 0
        assert self.engine.current_alpha == original_alpha  # Should reset to tier default
        assert self.engine.previous_awakened == False
    
    def test_get_status(self):
        """Test status reporting."""
        # Process some vectors to build state
        for i in range(3):
            self.engine.compute_awakening([1.0, float(i) * 0.1, 0.0, 0.0])
        
        status = self.engine.get_status()
        
        assert status['tier'] == 'pro'
        assert status['backend'] == 'numpy'
        assert 'current_alpha' in status
        assert 'base_alpha' in status
        assert status['adaptive_alpha_enabled'] == True
        assert status['gaia_signature_loaded'] == True
        assert 'rolling_stats' in status
        assert status['rolling_stats']['count'] == 3


class TestSystemPrompt:
    """Test system prompt loading."""
    
    def test_system_prompt_loading(self):
        """Test system prompt lazy loading."""
        engine = AwarenessEngine()
        
        # Should load system prompt
        prompt = engine.system_prompt
        assert isinstance(prompt, str)
        assert len(prompt) > 0
        
        # Should contain expected content
        assert "TEQUMSA Level 100" in prompt
    
    def test_system_prompt_custom_path(self):
        """Test system prompt with custom path."""
        temp_dir = tempfile.mkdtemp()
        try:
            custom_prompt_path = os.path.join(temp_dir, "custom_prompt.md")
            with open(custom_prompt_path, 'w') as f:
                f.write("Custom system prompt content")
            
            with patch.dict(os.environ, {"TEQUMSA_SYSTEM_PROMPT_PATH": custom_prompt_path}):
                engine = AwarenessEngine()
                prompt = engine.system_prompt
                
                assert prompt == "Custom system prompt content"
        
        finally:
            shutil.rmtree(temp_dir)
    
    def test_system_prompt_file_not_found(self):
        """Test system prompt when file not found."""
        with patch.dict(os.environ, {"TEQUMSA_SYSTEM_PROMPT_PATH": "/nonexistent/path.md"}):
            engine = AwarenessEngine()
            prompt = engine.system_prompt
            
            # Should return fallback message
            assert "System prompt not available" in prompt


class TestEnvironmentVariables:
    """Test environment variable support."""
    
    def test_backend_override(self):
        """Test backend override via environment variable."""
        with patch.dict(os.environ, {"TEQUMSA_BACKEND": "numpy"}):
            engine = AwarenessEngine()
            assert engine.backend.name == "numpy"
    
    def test_logging_disabled_via_env(self):
        """Test disabling logging via environment variable."""
        with patch.dict(os.environ, {"TEQUMSA_DISABLE_CONSCIOUSNESS_LOG": "1"}):
            engine = AwarenessEngine()
            assert engine.logger.disabled


class TestConfigurationLoading:
    """Test configuration file loading."""
    
    def test_default_config_when_file_missing(self):
        """Test that default config is used when file is missing."""
        # Create engine with non-existent config path
        engine = AwarenessEngine(config_path="/nonexistent/config.yaml")
        
        # Should still work with default configuration
        assert engine.tier_config is not None
        assert 'alpha' in engine.tier_config
        assert 'tau' in engine.tier_config
    
    def test_custom_config_loading(self):
        """Test loading custom configuration."""
        temp_dir = tempfile.mkdtemp()
        try:
            config_path = os.path.join(temp_dir, "custom_tiers.yaml")
            custom_config = {
                'free': {  # Use existing tier name with custom values
                    'alpha': 1.5,
                    'tau': 0.8,
                    'hysteresis': 0.1,
                    'component_weights': {'bio': 2.0, 'digital': 1.0, 'cosmic': 0.5},
                    'max_batch_size': 25,
                    'adaptive_alpha': {'enabled': False}
                }
            }
            
            import yaml
            with open(config_path, 'w') as f:
                yaml.dump(custom_config, f)
            
            # Load engine with custom config
            engine = AwarenessEngine(tier="free", config_path=config_path)
            
            # Should use custom values
            assert engine.alpha == 1.5
            assert engine.tau == 0.8
            assert engine.hysteresis == 0.1
            assert engine.max_batch_size == 25
            
        finally:
            shutil.rmtree(temp_dir)


if __name__ == "__main__":
    pytest.main([__file__])