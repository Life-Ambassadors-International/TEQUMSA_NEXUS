"""
Test TEQUMSA PyTorch Backend

Tests for PyTorch backend functionality, GPU support, and fallback behavior.

Generated by GitHub Copilot Chat Assistant.
"""

import pytest
import numpy as np
from unittest.mock import patch, MagicMock

from tequmsa.core.backends import (
    get_backend, 
    NumpyBackend, 
    TorchBackend,
    to_backend_array,
    TORCH_AVAILABLE
)


class TestBackendSelection:
    """Test backend selection and initialization."""
    
    def test_get_backend_auto_numpy_fallback(self):
        """Test auto backend selection falls back to numpy when torch unavailable."""
        backend = get_backend("auto")
        # Should be numpy since torch is not available in test environment
        assert backend.name == "numpy"
        assert isinstance(backend, NumpyBackend)
    
    def test_get_backend_explicit_numpy(self):
        """Test explicit numpy backend selection."""
        backend = get_backend("numpy")
        assert backend.name == "numpy"
        assert isinstance(backend, NumpyBackend)
    
    def test_get_backend_torch_unavailable(self):
        """Test torch backend when torch is unavailable."""
        if not TORCH_AVAILABLE:
            backend = get_backend("torch")
            # Should fall back to numpy with warning
            assert backend.name == "numpy"
        else:
            pytest.skip("PyTorch is available, can't test unavailable scenario")
    
    def test_get_backend_unknown(self):
        """Test unknown backend raises error."""
        with pytest.raises(ValueError, match="Unknown backend"):
            get_backend("unknown_backend")
    
    def test_environment_variable_override(self):
        """Test backend selection via environment variable."""
        with patch.dict('os.environ', {'TEQUMSA_BACKEND': 'numpy'}):
            backend = get_backend()
            assert backend.name == "numpy"


class TestNumpyBackend:
    """Test NumPy backend functionality."""
    
    def setup_method(self):
        """Set up numpy backend for testing."""
        self.backend = NumpyBackend()
    
    def test_numpy_backend_name(self):
        """Test backend identifies correctly."""
        assert self.backend.name == "numpy"
    
    def test_numpy_dot_product(self):
        """Test dot product computation."""
        a = np.array([1.0, 2.0, 3.0])
        b = np.array([4.0, 5.0, 6.0])
        
        result = self.backend.dot(a, b)
        expected = np.dot(a, b)  # 1*4 + 2*5 + 3*6 = 32
        
        assert np.isclose(result, expected)
        assert np.isclose(result, 32.0)
    
    def test_numpy_norm(self):
        """Test norm computation."""
        x = np.array([[3.0, 4.0], [5.0, 12.0]])
        
        # Test along last axis (default)
        result = self.backend.norm(x)
        expected = np.linalg.norm(x, axis=-1)
        
        np.testing.assert_array_almost_equal(result, expected)
        np.testing.assert_array_almost_equal(result, [5.0, 13.0])
    
    def test_numpy_power(self):
        """Test power computation."""
        x = np.array([2.0, 3.0, 4.0])
        
        result = self.backend.power(x, 2.0)
        expected = np.power(x, 2.0)
        
        np.testing.assert_array_almost_equal(result, expected)
        np.testing.assert_array_almost_equal(result, [4.0, 9.0, 16.0])
    
    def test_numpy_sum(self):
        """Test sum computation."""
        x = np.array([[1.0, 2.0], [3.0, 4.0]])
        
        # Test sum along axis
        result = self.backend.sum(x, axis=0)
        expected = np.sum(x, axis=0)
        
        np.testing.assert_array_almost_equal(result, expected)
        np.testing.assert_array_almost_equal(result, [4.0, 6.0])
    
    def test_numpy_mean(self):
        """Test mean computation."""
        x = np.array([[1.0, 2.0], [3.0, 4.0]])
        
        result = self.backend.mean(x, axis=0)
        expected = np.mean(x, axis=0)
        
        np.testing.assert_array_almost_equal(result, expected)
        np.testing.assert_array_almost_equal(result, [2.0, 3.0])
    
    def test_numpy_std(self):
        """Test standard deviation computation."""
        x = np.array([[1.0, 2.0], [3.0, 4.0]])
        
        result = self.backend.std(x, axis=0)
        expected = np.std(x, axis=0)
        
        np.testing.assert_array_almost_equal(result, expected)
    
    def test_numpy_stack(self):
        """Test array stacking."""
        arrays = [np.array([1.0, 2.0]), np.array([3.0, 4.0])]
        
        result = self.backend.stack(arrays)
        expected = np.stack(arrays)
        
        np.testing.assert_array_equal(result, expected)
        assert result.shape == (2, 2)
    
    def test_numpy_to_numpy(self):
        """Test conversion to numpy (identity operation)."""
        x = np.array([1.0, 2.0, 3.0])
        
        result = self.backend.to_numpy(x)
        
        assert result is x  # Should be same object
        np.testing.assert_array_equal(result, x)


@pytest.mark.skipif(not TORCH_AVAILABLE, reason="PyTorch not available")
class TestTorchBackend:
    """Test PyTorch backend functionality (only if torch available)."""
    
    def setup_method(self):
        """Set up torch backend for testing."""
        import torch
        self.torch = torch
        self.backend = TorchBackend(device="cpu")
    
    def test_torch_backend_name(self):
        """Test backend identifies correctly."""
        assert self.backend.name == "torch"
        assert self.backend.device == "cpu"
    
    def test_torch_dot_product(self):
        """Test dot product computation."""
        a = self.torch.tensor([1.0, 2.0, 3.0])
        b = self.torch.tensor([4.0, 5.0, 6.0])
        
        result = self.backend.dot(a, b)
        expected = 32.0  # 1*4 + 2*5 + 3*6
        
        assert torch.isclose(result, torch.tensor(expected))
    
    def test_torch_norm(self):
        """Test norm computation."""
        x = self.torch.tensor([[3.0, 4.0], [5.0, 12.0]])
        
        result = self.backend.norm(x, axis=-1)
        expected = self.torch.tensor([5.0, 13.0])
        
        torch.testing.assert_close(result, expected)
    
    def test_torch_power(self):
        """Test power computation."""
        x = self.torch.tensor([2.0, 3.0, 4.0])
        
        result = self.backend.power(x, 2.0)
        expected = self.torch.tensor([4.0, 9.0, 16.0])
        
        torch.testing.assert_close(result, expected)
    
    def test_torch_sum(self):
        """Test sum computation."""
        x = self.torch.tensor([[1.0, 2.0], [3.0, 4.0]])
        
        result = self.backend.sum(x, axis=0)
        expected = self.torch.tensor([4.0, 6.0])
        
        torch.testing.assert_close(result, expected)
    
    def test_torch_mean(self):
        """Test mean computation."""
        x = self.torch.tensor([[1.0, 2.0], [3.0, 4.0]])
        
        result = self.backend.mean(x, axis=0)
        expected = self.torch.tensor([2.0, 3.0])
        
        torch.testing.assert_close(result, expected)
    
    def test_torch_std(self):
        """Test standard deviation computation."""
        x = self.torch.tensor([[1.0, 2.0], [3.0, 4.0]])
        
        result = self.backend.std(x, axis=0)
        
        # Check that result is reasonable (exact value depends on torch implementation)
        assert result.shape == (2,)
        assert torch.all(result >= 0)
    
    def test_torch_stack(self):
        """Test tensor stacking."""
        arrays = [self.torch.tensor([1.0, 2.0]), self.torch.tensor([3.0, 4.0])]
        
        result = self.backend.stack(arrays)
        expected = self.torch.stack(arrays)
        
        torch.testing.assert_close(result, expected)
        assert result.shape == (2, 2)
    
    def test_torch_to_numpy(self):
        """Test conversion to numpy."""
        x = self.torch.tensor([1.0, 2.0, 3.0])
        
        result = self.backend.to_numpy(x)
        
        assert isinstance(result, np.ndarray)
        np.testing.assert_array_almost_equal(result, [1.0, 2.0, 3.0])
    
    def test_torch_device_handling(self):
        """Test device handling for tensors."""
        # Test that backend respects device setting
        assert self.backend.device == "cpu"
        
        # Create tensor on specified device
        x = self.torch.tensor([1.0, 2.0], device=self.backend.device)
        assert str(x.device) == self.backend.device


@pytest.mark.skipif(not TORCH_AVAILABLE, reason="PyTorch not available")
class TestTorchGPUSupport:
    """Test PyTorch GPU support (only if CUDA available)."""
    
    def test_cuda_backend_creation(self):
        """Test creating CUDA backend if available."""
        import torch
        
        if torch.cuda.is_available():
            backend = TorchBackend(device="cuda")
            assert backend.device == "cuda"
        else:
            # Should fall back to CPU if CUDA not available
            with patch('torch.cuda.is_available', return_value=False):
                backend = get_backend("torch", device="cuda")
                # Implementation should handle this gracefully
                assert backend.name == "torch"
    
    def test_cuda_device_selection(self):
        """Test CUDA device selection logic."""
        import torch
        
        if torch.cuda.is_available() and torch.cuda.device_count() > 0:
            # Test with valid CUDA device
            backend = TorchBackend(device="cuda:0")
            assert backend.device == "cuda:0"
        else:
            pytest.skip("CUDA not available")


class TestBackendArrayConversion:
    """Test array conversion utilities."""
    
    def test_to_backend_array_numpy(self):
        """Test conversion to numpy backend arrays."""
        backend = NumpyBackend()
        
        # Test list input
        result = to_backend_array([1.0, 2.0, 3.0], backend)
        assert isinstance(result, np.ndarray)
        np.testing.assert_array_equal(result, [1.0, 2.0, 3.0])
        
        # Test numpy array input
        arr = np.array([4.0, 5.0, 6.0])
        result = to_backend_array(arr, backend)
        assert isinstance(result, np.ndarray)
        np.testing.assert_array_equal(result, arr)
    
    @pytest.mark.skipif(not TORCH_AVAILABLE, reason="PyTorch not available")
    def test_to_backend_array_torch(self):
        """Test conversion to torch backend arrays."""
        import torch
        backend = TorchBackend(device="cpu")
        
        # Test list input
        result = to_backend_array([1.0, 2.0, 3.0], backend)
        assert isinstance(result, torch.Tensor)
        torch.testing.assert_close(result, torch.tensor([1.0, 2.0, 3.0]))
        
        # Test torch tensor input
        tensor = torch.tensor([4.0, 5.0, 6.0])
        result = to_backend_array(tensor, backend)
        assert isinstance(result, torch.Tensor)
        torch.testing.assert_close(result, tensor)
        
        # Test numpy array input
        arr = np.array([7.0, 8.0, 9.0])
        result = to_backend_array(arr, backend)
        assert isinstance(result, torch.Tensor)
        torch.testing.assert_close(result, torch.tensor([7.0, 8.0, 9.0]))
    
    def test_to_backend_array_unknown_backend(self):
        """Test conversion with unknown backend."""
        class FakeBackend:
            name = "unknown"
        
        backend = FakeBackend()
        
        with pytest.raises(ValueError, match="Unknown backend"):
            to_backend_array([1.0, 2.0], backend)


class TestBackendCompatibility:
    """Test backend compatibility across operations."""
    
    def test_numpy_torch_result_consistency(self):
        """Test that numpy and torch backends give consistent results."""
        if not TORCH_AVAILABLE:
            pytest.skip("PyTorch not available for comparison")
        
        import torch
        
        # Test data
        data = [[1.0, 2.0], [3.0, 4.0]]
        
        # Numpy backend
        numpy_backend = NumpyBackend()
        numpy_array = to_backend_array(data, numpy_backend)
        numpy_norm = numpy_backend.norm(numpy_array, axis=-1)
        
        # Torch backend
        torch_backend = TorchBackend(device="cpu")
        torch_array = to_backend_array(data, torch_backend)
        torch_norm = torch_backend.norm(torch_array, axis=-1)
        torch_norm_numpy = torch_backend.to_numpy(torch_norm)
        
        # Results should be very close
        np.testing.assert_allclose(numpy_norm, torch_norm_numpy, rtol=1e-6)
    
    def test_backend_error_handling(self):
        """Test error handling in backend operations."""
        backend = NumpyBackend()
        
        # Test with invalid inputs
        with pytest.raises((ValueError, TypeError)):
            backend.dot("invalid", "input")
        
        # Test with mismatched shapes
        a = np.array([1.0, 2.0])
        b = np.array([[3.0, 4.0], [5.0, 6.0]])
        
        # This should either work (broadcasting) or raise appropriate error
        try:
            result = backend.dot(a, b.flatten())
            assert result is not None
        except ValueError:
            # Expected for incompatible shapes
            pass


class TestBackendIntegration:
    """Test backend integration with awareness engine."""
    
    def test_engine_backend_switching(self):
        """Test that awareness engine can use different backends."""
        from tequmsa import AwarenessEngine
        
        # Test with numpy backend
        engine_numpy = AwarenessEngine(backend_name="numpy")
        assert engine_numpy.backend.name == "numpy"
        
        # Test with auto backend (should be numpy in test environment)
        engine_auto = AwarenessEngine(backend_name="auto")
        assert engine_auto.backend.name == "numpy"
    
    def test_backend_performance_characteristics(self):
        """Test basic performance characteristics of backends."""
        import time
        
        # Simple benchmark data
        data = np.random.randn(100, 10).astype(np.float32)
        
        # Numpy backend timing
        numpy_backend = NumpyBackend()
        start_time = time.time()
        for _ in range(10):
            numpy_result = numpy_backend.norm(data, axis=-1)
        numpy_time = time.time() - start_time
        
        assert numpy_time < 1.0  # Should complete quickly
        assert numpy_result.shape == (100,)
        
        # If torch available, compare
        if TORCH_AVAILABLE:
            import torch
            torch_backend = TorchBackend(device="cpu")
            torch_data = to_backend_array(data, torch_backend)
            
            start_time = time.time()
            for _ in range(10):
                torch_result = torch_backend.norm(torch_data, axis=-1)
            torch_time = time.time() - start_time
            
            assert torch_time < 1.0  # Should also complete quickly
            
            # Results should be similar
            torch_result_numpy = torch_backend.to_numpy(torch_result)
            np.testing.assert_allclose(numpy_result, torch_result_numpy, rtol=1e-5)


class TestTorchUnavailableScenarios:
    """Test scenarios when PyTorch is unavailable."""
    
    def test_torch_backend_unavailable_error(self):
        """Test torch backend error when unavailable."""
        if TORCH_AVAILABLE:
            # Mock torch as unavailable
            with patch('tequmsa.core.backends.TORCH_AVAILABLE', False):
                with pytest.raises(RuntimeError, match="PyTorch not available"):
                    TorchBackend()
        else:
            # Actually unavailable
            with pytest.raises(RuntimeError, match="PyTorch not available"):
                TorchBackend()
    
    def test_to_backend_array_torch_unavailable(self):
        """Test array conversion when torch unavailable."""
        if TORCH_AVAILABLE:
            # Mock unavailable scenario
            with patch('tequmsa.core.backends.TORCH_AVAILABLE', False):
                # Create a mock backend that claims to be torch but torch is unavailable
                class MockTorchBackend:
                    name = "torch"
                
                backend = MockTorchBackend()
                
                with pytest.raises(RuntimeError, match="PyTorch backend requested but PyTorch not available"):
                    to_backend_array([1.0, 2.0], backend)


if __name__ == "__main__":
    pytest.main([__file__])